{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from src.perceptron import Perceptron\n",
    "from src.adaline import Adaline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './resources/winequality-red.csv'\n",
    "\n",
    "try:\n",
    "    wine_data = pd.read_csv(dataset_path, sep=';')\n",
    "except FileNotFoundError:\n",
    "    print('[-] Set `dataset_path` with correct value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "# V.1 Exploring the green reds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Write a function that will plot a scatterplot matrix of your red wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_matrix(wine_data, good_threshold, bad_threshold, save_plot=False):\n",
    "    \"\"\"\n",
    "    Plots a scatterplot matrix of data. Samples with quality over `good_threshold`\n",
    "    are plotted as one color and samples below `bad_threshold` as another.\n",
    "\n",
    "    :param pd.DataFrame wine_data:\n",
    "    :param int good_threshold:\n",
    "    :param int bad_threshold:\n",
    "\n",
    "    :returns: result matplotlib.pyplot.figure object\n",
    "    \"\"\"\n",
    "    num_samples, num_features = wine_data.shape\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_features,\n",
    "                             ncols=num_features, figsize=(18,18))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "    \n",
    "    feature_names = wine_data.columns\n",
    "    for i, label in enumerate(feature_names):\n",
    "        axes[i, i].annotate(label, (0.5, 0.5), xycoords='axes fraction',\n",
    "                            ha='center', va='center')\n",
    "    \n",
    "    good_wines = wine_data[(wine_data['quality'] > good_threshold)]\n",
    "    bad_wines = wine_data[(wine_data['quality'] < bad_threshold)]\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        for j in range(i + 1, num_features):\n",
    "            axes[i, j].scatter(good_wines.iloc[:, j], good_wines.iloc[:, i], c=['g'], marker='.')\n",
    "            axes[i, j].scatter(bad_wines.iloc[:, j], bad_wines.iloc[:, i], c=['r'], marker='.')\n",
    "            axes[j, i].scatter(good_wines.iloc[:, i], good_wines.iloc[:, j], c=['g'], marker='.')\n",
    "            axes[j, i].scatter(bad_wines.iloc[:, i], bad_wines.iloc[:, j], c=['r'], marker='.')\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig('./scatterplot-matrix.png')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_scatter_matrix(wine_data, 7, 4, True)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Which factors do you think will be most useful to your perceptron for distinguishing high quality vs. low quality wines? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron, being a linear model, works best on linearly separable data.\n",
    "\n",
    "- **'alcohol'**, **'pH'**, **'sulphates'** look like good features for classification; \n",
    "- **'density'**, **'chlorides'** are bad features and most likely won't help;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------\n",
    "# V.2 Learning to perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) & b) Implementing Perceptron\n",
    "- Implement Rosenblatt perceptron with randomly initialized weights and bias, heaviside step activation function\n",
    "- Train your perceptron on 2 chemical factors (for example, alcohol and pH) and only use wines with a score of 8 or higher and wines with a score of 3 or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the wine as good, if it's quality > 5\n",
    "wine_data = wine_data.assign(goodness=pd.Series(wine_data['quality'] > 5))\n",
    "\n",
    "# selecting the subset from `wine_data`\n",
    "# only use wines with a score of 8 or higher and wines with a score of 3 or lower\n",
    "features = ['volatile acidity', 'alcohol', 'quality', 'goodness']\n",
    "selected_wine_data = wine_data[(wine_data['quality'] > 7) | (wine_data['quality'] < 4)][features]\n",
    "selected_wine_data = selected_wine_data.reset_index(drop=True)\n",
    "\n",
    "X = selected_wine_data.loc[:, ['volatile acidity', 'alcohol']]\n",
    "Y = selected_wine_data['goodness'].values\n",
    "\n",
    "print('{} samples selected:\\n'.format(selected_wine_data.shape[0]))\n",
    "print(selected_wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_init(shape, mode='rand'):\n",
    "    \"\"\"\n",
    "    :param shape: an int or tuple, shape of the array to init\n",
    "    :param mode: 'rand' | 'zeros' | 'ones'\n",
    "    \"\"\"\n",
    "    \n",
    "    if mode not in ('rand', 'zeros', 'ones'):\n",
    "        raise ValueError('invalid mode')\n",
    "    \n",
    "    new_shape = shape\n",
    "    if isinstance(shape, int):\n",
    "        new_shape = (shape, 1)\n",
    "    \n",
    "    if isinstance(shape, tuple) and len(shape) == 1:\n",
    "        new_shape = (shape[0], 1)\n",
    "    \n",
    "    base_dict = {}\n",
    "    for i in range(new_shape[1]):\n",
    "        if mode == 'rand':\n",
    "            base_dict[i] = [0.0001 * random.uniform(-1, 1) for i in range(new_shape[0])]\n",
    "        elif mode == 'zeros':\n",
    "            base_dict[i] = new_shape[0] * [0.0]\n",
    "        elif mode == 'ones':\n",
    "            base_dict[i] = new_shape[0] * [1.0]\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(base_dict)\n",
    "    \n",
    "    if isinstance(shape, int) or isinstance(shape, tuple) and len(shape) == 1:\n",
    "        return df.values.squeeze()\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Perceptron(lr=0.005)\n",
    "\n",
    "train_stats = p.train(X.values, Y, epochs=1000, verbose=True, seed=1699)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Training procedure visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_num_errors(ax, performance, epoch):\n",
    "    epochs = [elem[0] for elem in performance[:epoch + 1]]\n",
    "    epoch_errors = [elem[1] for elem in performance[:epoch + 1]]\n",
    "\n",
    "    ax.plot(epochs, epoch_errors)\n",
    "    ax.set_xlim([0, len(performance)])\n",
    "    ax.set_title('Errors as a function of epochs')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('classification errors')\n",
    "\n",
    "\n",
    "def draw_decision_boundary(ax, performance, epoch, wine_data, features):\n",
    "    x_min = wine_data.loc[:, features[0]].min() - 0.15\n",
    "    x_max = wine_data.loc[:, features[0]].max() + 0.15\n",
    "    y_min = wine_data.loc[:, features[1]].min() - 0.15\n",
    "    y_max = wine_data.loc[:, features[1]].max() + 0.15\n",
    "    \n",
    "    ax.set_title('Decision boundary at epoch {}'.format(epoch))\n",
    "    ax.set_xlabel(features[0])\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylabel(features[1])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    \n",
    "    w2, w1 = performance[epoch][2]\n",
    "    b = performance[epoch][3]\n",
    "    slope = -w1/w2\n",
    "    intercept = -b/w2\n",
    "    x_coords = range(int(x_min) - 1, int(x_max) + 2)\n",
    "    y_coords = slope * x_coords + intercept\n",
    "\n",
    "    ax.plot(x_coords, y_coords, 'b--', label='Decision boundary')\n",
    "    ax.fill_between(x_coords, y_coords, y_min, color='#99ff99')\n",
    "    ax.fill_between(x_coords, y_coords, y_max, color='#ff9999')\n",
    "\n",
    "\n",
    "def draw_scatter(ax, wine_data, features, good_thresh, bad_thresh):\n",
    "    good_wines = wine_data[(wine_data['quality'] > good_thresh)]\n",
    "    bad_wines = wine_data[(wine_data['quality'] < bad_thresh)]\n",
    "\n",
    "    ax.scatter(good_wines.loc[:, features[0]], good_wines.loc[:, features[1]],\n",
    "                    c=['g'], label='good wines (> {} score)'.format(good_thresh))\n",
    "    ax.scatter(bad_wines.loc[:, features[0]], bad_wines.loc[:, features[1]],\n",
    "                    c=['r'], label='bad wines (< {} score)'.format(bad_thresh))\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "    \n",
    "def plot_performance(performance, wine_data, features, good_thresh, bad_thresh,\n",
    "                     epoch=-1, save_plot=False, save_name='./train_stats.png'):\n",
    "    \"\"\"\n",
    "    Plot the performance of perceptron or adaline.\n",
    "    This function will produce a two plot figure:\n",
    "    1) Number of classification errors as a function of epochs\n",
    "    2) Decision boundary for two factors\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "    \n",
    "    if epoch > len(performance) - 1:\n",
    "        raise ValueError('number of epochs should be less than {}'.format(len(performance)))\n",
    "    \n",
    "    if len(features) != 2:\n",
    "        raise ValueError('number of features should be 2')\n",
    "    \n",
    "    if epoch == -1:\n",
    "        epoch = len(performance) - 1\n",
    "\n",
    "    draw_num_errors(axes[0], performance, epoch)    \n",
    "    draw_decision_boundary(axes[1], performance, epoch, wine_data, features)\n",
    "    draw_scatter(axes[1], wine_data, features, good_thresh, bad_thresh)\n",
    "    \n",
    "    if save_plot:\n",
    "        plt.savefig(save_name)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_performance(train_stats, selected_wine_data, ['alcohol', 'volatile acidity'], 7, 4, -1, False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# VI.2 Do perceptrons dream of electric sheep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_animation(performance, data, features, good_thresh, bad_thresh,\n",
    "                   num_frames=-1, name='performance_animation.html'):\n",
    "    if len(features) != 2:\n",
    "        raise ValueError('number of features should be 2')\n",
    "    \n",
    "    if num_frames > len(performance) - 1:\n",
    "            raise ValueError('num_frames should be less than {}'.format(len(performance)))\n",
    "    \n",
    "    if num_frames == -1:\n",
    "        num_frames = len(performance) - 1\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5), dpi=150)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "\n",
    "    def init():\n",
    "        imobj.set_data(array_init((360, 1000), mode='zeros'))\n",
    "\n",
    "        return imobj,\n",
    "\n",
    "    def animate(i, performance, data, features, good_thresh, bad_thresh):\n",
    "        fname = './train_stats_{}.png'.format(i)\n",
    "        plot_performance(performance, data, features, good_thresh, bad_thresh,\n",
    "                                   epoch=i, save_plot=True, save_name=fname)\n",
    "        img = mpimg.imread(fname)[-1::-1]\n",
    "        imobj.set_data(img)\n",
    "        os.remove(fname)\n",
    "\n",
    "        return imobj,\n",
    "\n",
    "    imobj = ax.imshow(array_init((360, 1000), mode='zeros'), interpolation='bilinear',\n",
    "                      origin='lower', alpha=1.0, zorder=1, aspect=1)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   fargs=(performance, data, features, good_thresh, bad_thresh),\n",
    "                                   repeat=False, frames=range(num_frames),\n",
    "                                   interval=120, blit=True)\n",
    "    anim.save(name)\n",
    "    print('[+] Animation saved as {}'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Feature Scaling\n",
    "\n",
    "`x* = (x - average(x)) / (max(x) - min(x))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(series):\n",
    "    \"\"\"\n",
    "    Perform mean normalization of pandas.Series\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(series, pd.Series):\n",
    "        raise ValueError('input argument is not an instance of pandas.Series class')\n",
    "\n",
    "    return (series - series.mean()) / (series.max() - series.min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_wine_data['volatile acidity'] = normalize_series(selected_wine_data['volatile acidity'])\n",
    "selected_wine_data['alcohol'] = normalize_series(selected_wine_data['alcohol'])\n",
    "\n",
    "X = selected_wine_data.loc[:, ['volatile acidity', 'alcohol']]\n",
    "Y = selected_wine_data['goodness'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Perceptron(lr=0.005)\n",
    "\n",
    "train_stats = p.train(X.values, Y, 100, verbose=True, seed=1699)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_performance(train_stats, selected_wine_data, ['alcohol', 'volatile acidity'], 7, 4, -1, False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "# V.3 My fair ADALINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Marvin notices and chides you for torturing your perceptron. Why?\n",
    "\n",
    "Let's try to distinguish between wines with a score of 4 and lower, and wines with a score of 7 and higher. We'll see, that perceptron does not learn on this data.\n",
    "\n",
    "It happens because single layer perceptrons are only capable of learning linearly separable patterns. The perceptron learning algorithm does not terminate if the learning set is not linearly separable, it will just never reach a point where all vectors are classified properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['volatile acidity', 'alcohol', 'quality', 'goodness']\n",
    "selected_wine_data = wine_data[(wine_data['quality'] > 6) | (wine_data['quality'] < 5)][features]\n",
    "selected_wine_data = selected_wine_data.reset_index(drop=True)\n",
    "\n",
    "selected_wine_data['volatile acidity'] = normalize_series(selected_wine_data['volatile acidity'])\n",
    "selected_wine_data['alcohol'] = normalize_series(selected_wine_data['alcohol'])\n",
    "\n",
    "X = selected_wine_data.loc[:, ['volatile acidity', 'alcohol']]\n",
    "Y = selected_wine_data['goodness']\n",
    "\n",
    "print('{} samples selected:\\n'.format(X.shape[0]))\n",
    "print(X[:10])\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Perceptron(lr=0.001)\n",
    "\n",
    "train_stats = p.train(X.values, Y, 0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_performance(train_stats, selected_wine_data, ['alcohol', 'volatile acidity'], 6, 5, -1, False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) & c) Implementing ADALINE (Adaptive Linear Neuron)\n",
    "\n",
    "Adaline is similar to Perceptron and also belongs to the class of single layer binary classifiers. But there are some differences:\n",
    "- Adaline cost function is Sum Squared Error (SSE) instead of normal error of each training sample in Perceptron;\n",
    "- Adaline tries to minimize the cost function using Gradient Descent in contrast to Perceptron learning rule. This is an advantage of Adaline as it allows to calculate the error based on continous values rather than binary value;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Find a good learning rate for your ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying random search for learning rate tuning\n",
    "\n",
    "best_lr = 0\n",
    "min_errors = 999999\n",
    "for n in range(20):\n",
    "    lr = round(random.uniform(0.001, 0.05), 5)\n",
    "    ad = Adaline(lr)\n",
    "    \n",
    "    train_stats = ad.train(X.values, Y, 300, 'batch', verbose=False)\n",
    "    num_errors = min([elem[1] for elem in train_stats])\n",
    "    last_error = train_stats[-1][1]\n",
    "    \n",
    "    print('try: {}, lr: {}, last error: {}, {} min errors,'.format(n, lr, last_error, min_errors))\n",
    "    \n",
    "    if num_errors < min_errors:\n",
    "        min_errors = num_errors\n",
    "        best_lr = lr\n",
    "\n",
    "print(\"Best learnig rate: {}, num errors: {}\".format(best_lr, min_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad = Adaline(lr=best_lr)\n",
    "\n",
    "train_stats = ad.train(X.values, Y, 301, 'batch', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_performance(train_stats, selected_wine_data, ['alcohol', 'volatile acidity'], 6, 5, -1, False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## V.4 Advanced wine sampling and resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Write a function that uses the holdout method to partition the red wine data into a training and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(wine_data, test_size=0.7):\n",
    "    train_set = wine_data.sample(frac=test_size)\n",
    "    test_set = wine_data.drop(train_set.index)\n",
    "\n",
    "    print('Train set size: {}'.format(train_set.shape[0]))\n",
    "    print('Test set size: {}'.format(test_set.shape[0]))\n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(selected_wine_data, test_size=0.7)\n",
    "X_train = train_set.loc[:, ['volatile acidity', 'alcohol']]\n",
    "Y_train = train_set['goodness']\n",
    "\n",
    "X_test = test_set.loc[:, ['volatile acidity', 'alcohol']]\n",
    "Y_test = test_set['goodness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing our best model on test_set\n",
    "\n",
    "ad.evaluate_accuracy(X_test.values, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Write a function that generates a k-fold cross-validation dataset from the red wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(data, k, shuffle=True):\n",
    "    folds = []\n",
    "    \n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    for i in range(k):\n",
    "        fold_size = data.shape[0] // k + 1 if i < data.shape[0] % k else data.shape[0] // k\n",
    "        test_data = data.iloc[i * fold_size: (i + 1) * fold_size, :]\n",
    "        train_data = data.iloc[data.index.difference(test_data.index), :]\n",
    "        folds.append((train_data, test_data))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 9\n",
    "folds = k_fold_split(selected_wine_data, 9)\n",
    "\n",
    "print('train, val lengths for {} folds: {}'.format(\n",
    "    num_folds, [(len(train), len(val)) for train, val in folds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_folds(folds, features):\n",
    "    fig, axes = plt.subplots(ncols=len(folds), figsize=(13,5))\n",
    "    \n",
    "    for i, fold in enumerate(folds):\n",
    "        if i != 0:\n",
    "            axes[i].yaxis.set_visible(False)\n",
    "        axes[i].scatter(fold[0].loc[:, features[0]], fold[0].loc[:, features[1]],\n",
    "                    c=['g'], label='training data')\n",
    "        axes[i].scatter(fold[1].loc[:, features[0]], fold[1].loc[:, features[1]],\n",
    "                        c=['r'], label='test data')\n",
    "        \n",
    "        axes[i].set_xlabel(features[0])\n",
    "        axes[i].set_ylabel(features[1])\n",
    "    \n",
    "    axes[len(folds) - 1].legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_folds(folds, ['alcohol', 'volatile acidity'])\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) ADALINE evaluation via k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_adaline(folds, features, lr=0.05, epochs=500, mode='batch', verbose=False):\n",
    "    sum_accuracy = 0\n",
    "\n",
    "    for i, fold in enumerate(folds):\n",
    "        X_train = fold[0][features]\n",
    "        Y_train = fold[0]['goodness']\n",
    "        \n",
    "        ad = Adaline(lr=lr)\n",
    "        train_stats = ad.train(X_train.values, Y_train, epochs, mode, verbose)\n",
    "        \n",
    "        X_test = fold[1][features]\n",
    "        Y_test = fold[1]['goodness']\n",
    "        accuracy = ad.evaluate_accuracy(X_test.values, Y_test)\n",
    "        sum_accuracy += accuracy\n",
    "    \n",
    "    print('=================================')\n",
    "    print('Mean model accuracy: {0:.3f}'.format(sum_accuracy / len(folds)))\n",
    "    print('=================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small learning rate and few epochs --> lower accuracy\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity'], lr=0.0005,\n",
    "                       epochs=100, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good learning rate allows to train quickly and gives good accuracy\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity'], lr=0.05,\n",
    "                       epochs=50, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And training longer doesn't help\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity'], lr=0.05,\n",
    "                       epochs=500, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If learning rate is too big, we will overshoot the point of minimum\n",
    "# and get lower accuracy\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity'], lr=0.5,\n",
    "                       epochs=200, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## V.5 adventures in the Nth dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Training on more chemical factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pH', 'alcohol', 'sulphates', 'fixed acidity', 'volatile acidity', 'goodness', 'quality']\n",
    "selected_wine_data = wine_data[(wine_data['quality'] > 6) | (wine_data['quality'] < 5)][features]\n",
    "selected_wine_data = selected_wine_data.reset_index(drop=True)\n",
    "\n",
    "norm_features = ['pH', 'alcohol', 'sulphates', 'fixed acidity', 'volatile acidity']\n",
    "for feature in norm_features:\n",
    "    selected_wine_data[feature] = normalize_series(selected_wine_data[feature])\n",
    "\n",
    "print(selected_wine_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = k_fold_split(selected_wine_data, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 'pH' to taining features\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity', 'pH'], lr=0.05,\n",
    "                       epochs=200, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'pH' -> 'sulphates'\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity', 'sulphates'], lr=0.05,\n",
    "                       epochs=200, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + 'fixed acidity'\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity', 'fixed acidity', 'sulphates'], lr=0.05,\n",
    "                       epochs=200, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'fixed acidity' -> 'pH'\n",
    "\n",
    "cross_validate_adaline(folds, ['alcohol', 'volatile acidity', 'pH', 'sulphates'], lr=0.05,\n",
    "                       epochs=200, mode='batch', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) What does the decision boundary for N factors look like?\n",
    "Decision boundary for N factors is (N - 1) dimentional hyperplane "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# V.6 Marvin's rebuttal\n",
    "\n",
    "Find a way to successfully classify the Pan-Galactic Gargle Blaster dataset.\n",
    "Show that your perceptron or ADALINE successfully classifies the Pan-Galactic Gargle Blaster data set by plotting the decision boundary and also show ‘good’ and ‘bad’ Gargle Blaster data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './resources/Pan Galactic Gargle Blaster.csv'\n",
    "\n",
    "try:\n",
    "    gargle_blaster_data = pd.read_csv(dataset_path, sep=';')\n",
    "except FileNotFoundError:\n",
    "    print('[-] Set `dataset_path` with correct value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the gargle blaster as good, if it's quality > 5\n",
    "gargle_blaster_data = gargle_blaster_data.assign(goodness=pd.Series(gargle_blaster_data['quality'] > 5))\n",
    "\n",
    "# normalize feature series\n",
    "gargle_blaster_data['wonderflonium'] = normalize_series(gargle_blaster_data['wonderflonium'])\n",
    "gargle_blaster_data['fallian marsh gas'] = normalize_series(gargle_blaster_data['fallian marsh gas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scatter_matrix(gargle_blaster_data, 6, 5, True)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is not linearly separable, so neither Perceptron, nor ADALINE will not learn from it.\n",
    "\n",
    "The trick is to transform data points to polar coordinate system, where they will be perfectly separable with a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = gargle_blaster_data.loc[:, 'wonderflonium']\n",
    "x2 = gargle_blaster_data.loc[:, 'fallian marsh gas']\n",
    "\n",
    "# compute r and phi, needed for polar coordinates and add them to DataFrame\n",
    "gargle_blaster_data = gargle_blaster_data.assign(r=pd.Series(x1 * x1 + x2 * x2).pow(1./2))\n",
    "gargle_blaster_data = gargle_blaster_data.assign(\n",
    "    phi=pd.Series([math.atan2(x, y) for (x, y) in zip(x1, x2)]))\n",
    "\n",
    "print(gargle_blaster_data.iloc[:10])\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(gargle_blaster_data, test_size=0.7)\n",
    "\n",
    "X_train = train_set[['r', 'phi']]\n",
    "Y_train = train_set['goodness'].values\n",
    "\n",
    "X_test = test_set[['r', 'phi']]\n",
    "Y_test = test_set['goodness'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad = Adaline(lr=0.005)\n",
    "\n",
    "train_stats = ad.train(X_train.values, Y_train, 70, 'batch', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.evaluate_accuracy(X_test.values, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_performance(train_stats, train_set, ['phi', 'r'], 6, 5, -1, False)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
